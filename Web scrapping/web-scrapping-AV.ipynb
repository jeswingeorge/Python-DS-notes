{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](images/pune.jpg)\n",
    "\n",
    "# [Scrapping website of goibibo for hotels in Pune and their prices](https://www.goibibo.com/hotels/hotels-in-pune-ct/)\n",
    "\n",
    "\n",
    "Before scrapping any website check its __robots.txt__ file (which is also known as the robot exclusion protocol). This tells which pages/details not to crawl or scrap.\n",
    "\n",
    "![](images/robots.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the web page into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagret url to scrap\n",
    "url = \"https://www.goibibo.com/hotels/hotels-in-pune-ct/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above fetches our web page from the URL, and stores the result in a \"response\" object called `r`. That response object has a `text` attribute, which contains the same HTML code we get when viewing the page source from chrome web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html><head><title>Hotels in Pune - Book 933 Pune Hotels with ùòÇùóΩùòÅùóº ùü±ùü¨% off @ ‚Çπ184</title><meta charset=\"utf-8\"/><meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/><meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/><meta content=\"Best Pune Hotels with upto 50% off from Goibibo. Check 111003 reviews and 56982 photos for 933  Pune Hotels. Use coupon code GETSETGO and grab best deals starting from  @ ‚Çπ184 on Pune online hotel booking. ‚úî Lowest Price Guarantee ‚úî \n"
     ]
    }
   ],
   "source": [
    "# print the first 500 characters of the HTML\n",
    "print(r.text[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing the HTML using Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above parses the HTML (stored in r.text) into a special object called soup that the Beautiful Soup library understands. In other words, __Beautiful Soup is reading the HTML and making sense of its structure__.\n",
    "\n",
    "(Note that __lxml__ is the parser included with the Python standard library, though other parsers can be used by Beautiful Soup. See [differences between parsers](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#differences-between-parsers) to learn more.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting all of the records\n",
    "\n",
    "Taking advantage of the patterns we noticed in the article formatting to build our dataset. __Each record will be tagged in a consistent way in the HTML. This is the pattern that allows us to build our dataset__.\n",
    "\n",
    "The Beautiful Soup methods required for this task are:\n",
    "\n",
    "1. find()\n",
    "2. find_all()\n",
    "\n",
    "There is an excellent tutorial on these methods [(Searching the tree)](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree) in the Beautiful Soup documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determing pattern\n",
    "\n",
    "![](images/goibibo_hotels.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.find_all('div', attrs = {'class': \"width100 fl htlListSeo hotel-tile-srp-container hotel-tile-srp-container-template new-htl-design-tile-main-block\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code searches the soup object for all `<div>` tags with the attribute __class=\"width100 fl htlListSeo hotel-tile-srp-container hotel-tile-srp-container-template new-htl-design-tile-main-block\"__. It returns a special Beautiful Soup object (called a \"ResultSet\") containing the search results.\n",
    "\n",
    "__results__ acts like a Python list, so we can check its length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 results, which seems reasonable given the length of the article. (If this number did not seem reasonable, we would examine the HTML further to determine if our assumptions about the patterns in the HTML were incorrect.)\n",
    "\n",
    "## Extracting the data (Hotel name)\n",
    "\n",
    "Web scraping is often an iterative process, in which you experiment with your code until it works exactly as you desire. To simplify the experimentation, we'll start by only working with the first record in the results object, and then later on we'll modify our code to use a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p style=\"font-size: 18px; font-weight: bolder; color: #141823;font-family: 'Quicksand', sans-serif;\">Mint Koregaon Park next to Osho Ashram</p>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result = results[0].find('p',\n",
    "              attrs = {'style':\"font-size: 18px; font-weight: bolder; color: #141823;font-family: 'Quicksand', sans-serif;\"})\n",
    "first_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although `first_result` may look like a Python string, you'll notice that there are no quote marks around it. Instead, it's another special Beautiful Soup object (called a \"Tag\") that has specific methods and attributes. \n",
    "\n",
    "Since we want __to extract the text between the opening and closing tags__, we can access its `text` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mint Koregaon Park next to Osho Ashram'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results[0].find('p',\n",
    "              attrs = {'style':\"font-size: 18px; font-weight: bolder; color: #141823;font-family: 'Quicksand', sans-serif;\"})\n",
    ".text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2499'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].find('li', attrs = {\"class\":\"htl-tile-discount-prc\"}).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can apply these two methods to either the initial soup object or a Tag object (such as first_result):\n",
    "\n",
    "- __find()__: searches for the first matching tag, and returns a Tag object\n",
    "- __find_all()__: searches for all matching tags, and returns a ResultSet object (which you can treat like a list of Tags)\n",
    "\n",
    "You can extract information from a Tag object (such as `first_result`) using these __two attributes__:\n",
    "\n",
    "- __text__: extracts the text of a Tag, and returns a string\n",
    "- __contents__: extracts the children of a Tag, and returns a list of Tags and strings\n",
    "\n",
    "It's important to keep track of whether you are interacting with a Tag, ResultSet, list, or string, because that affects which methods and attributes you can access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the dataset\n",
    "\n",
    "Now that we've figured out how to extract the hotel name and price, we can create a loop to repeat this process on all 10 results. We'll store the output in a list of tuples called records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = []\n",
    "for result in results:\n",
    "    hotel_name = result.find('p',\n",
    "        attrs = {'style':\"font-size: 18px; font-weight: bolder; color: #141823;font-family: 'Quicksand', sans-serif;\"}).text\n",
    "    price = result.find('li', attrs = {\"class\":\"htl-tile-discount-prc\"}).text\n",
    "    records.append((hotel_name, price))\n",
    "    \n",
    "len(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there were 10 results, we have 10 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mint Koregaon Park next to Osho Ashram', '2499'),\n",
       " ('The Deccan Royaale', '2299'),\n",
       " ('Park Central Comfort-e-Suites, Pune', '2501')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a tabular data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel Name</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mint Koregaon Park next to Osho Ashram</td>\n",
       "      <td>2499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Deccan Royaale</td>\n",
       "      <td>2299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Park Central Comfort-e-Suites, Pune</td>\n",
       "      <td>2501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hotel Mint Ivy Viman Nagar</td>\n",
       "      <td>2499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lemon Tree Premier, City Center Pune</td>\n",
       "      <td>4082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>THE E- SQUARE HOTEL</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Grand Tulip, Swargate</td>\n",
       "      <td>2430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kapila Business Hotel</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hotel Aurora Towers</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hotel Vinstar Serviced Apartments</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Hotel Name Price\n",
       "0  Mint Koregaon Park next to Osho Ashram  2499\n",
       "1                      The Deccan Royaale  2299\n",
       "2     Park Central Comfort-e-Suites, Pune  2501\n",
       "3              Hotel Mint Ivy Viman Nagar  2499\n",
       "4    Lemon Tree Premier, City Center Pune  4082\n",
       "5                     THE E- SQUARE HOTEL  3000\n",
       "6               The Grand Tulip, Swargate  2430\n",
       "7                   Kapila Business Hotel  2900\n",
       "8                     Hotel Aurora Towers  3000\n",
       "9       Hotel Vinstar Serviced Apartments  2200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(records, columns = [\"Hotel Name\", \"Price\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall code required to do the extraction\n",
    "\n",
    "\n",
    "```\n",
    "# importing required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# tagret url to scrap\n",
    "url = \"https://www.goibibo.com/hotels/hotels-in-pune-ct/\"\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "results = soup.find_all('div', attrs = {'class': \"width100 fl htlListSeo hotel-tile-srp-container hotel-tile-srp-container-template new-htl-design-tile-main-block\"})\n",
    "\n",
    "records = []\n",
    "for result in results:\n",
    "    hotel_name = result.find('p',\n",
    "        attrs = {'style':\"font-size: 18px; font-weight: bolder; color: #141823;font-family: 'Quicksand', sans-serif;\"}).text\n",
    "    price = result.find('li', attrs = {\"class\":\"htl-tile-discount-prc\"}).text\n",
    "    records.append((hotel_name, price))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(records, columns = [\"Hotel Name\", \"Price\"])\n",
    "print(df\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "1. [Analytics Vidhya: Introduction to Web Scraping in Python](https://www.analyticsvidhya.com/blog/2019/10/web-scraping-hands-on-introduction-python/)\n",
    "2. [Data school web-scrapping python](https://www.dataschool.io/python-web-scraping-of-president-trumps-lies/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
