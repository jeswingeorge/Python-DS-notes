{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H:\\\\Spark\\\\spark-3.0.0-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "sqlcontext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with Spark Dataframe\n",
    "\n",
    "All operations done in dataframe gets transformed into RDD operation at the backend.\n",
    "\n",
    "## 1.Importing csv files as a dataframe\n",
    "\n",
    "- Using SparkSession: `spark.read.csv()`\n",
    "- Using SQLContext: `sqlcontext.read.csv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv('iris/iris.csv', header =  True, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[Sepal_Length: string, Sepal_Width: string, Petal_Length: string, Petal_Width: string, Species: string]\n"
     ]
    }
   ],
   "source": [
    "print(df1)   # metadata about the the imported of objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert RDD to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['5.1', '3.5', '1.4', '0.2', 'setosa'],\n",
       " ['4.9', '3.0', '1.4', '0.2', 'setosa'],\n",
       " ['4.7', '3.2', '1.3', '0.2', 'setosa'],\n",
       " ['4.6', '3.1', '1.5', '0.2', 'setosa'],\n",
       " ['5.0', '3.6', '1.4', '0.2', 'setosa']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris1 = sc.textFile('iris/iris_site.csv').map(lambda line: line.split(','))\n",
    "iris1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+------+\n",
      "| _1| _2| _3| _4|    _5|\n",
      "+---+---+---+---+------+\n",
      "|5.1|3.5|1.4|0.2|setosa|\n",
      "|4.9|3.0|1.4|0.2|setosa|\n",
      "|4.7|3.2|1.3|0.2|setosa|\n",
      "|4.6|3.1|1.5|0.2|setosa|\n",
      "|5.0|3.6|1.4|0.2|setosa|\n",
      "+---+---+---+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = spark.createDataFrame(iris1)\n",
    "temp.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert Dataframe to RDD\n",
    "\n",
    "Dataframe can be converted back to RDD by combining __RDD__ and __map__ object. Dataframe is converted to __rdd__ by RDD object and __map__ object places each row inside a tuple. If tuple is replaced by keyword __list__ then each row would be placed inside a list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5.1', '3.5', '1.4', '0.2', 'setosa'),\n",
       " ('4.9', '3.0', '1.4', '0.2', 'setosa'),\n",
       " ('4.7', '3.2', '1.3', '0.2', 'setosa'),\n",
       " ('4.6', '3.1', '1.5', '0.2', 'setosa'),\n",
       " ('5.0', '3.6', '1.4', '0.2', 'setosa')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.rdd.map(tuple).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['5.1', '3.5', '1.4', '0.2', 'setosa'],\n",
       " ['4.9', '3.0', '1.4', '0.2', 'setosa'],\n",
       " ['4.7', '3.2', '1.3', '0.2', 'setosa'],\n",
       " ['4.6', '3.1', '1.5', '0.2', 'setosa'],\n",
       " ['5.0', '3.6', '1.4', '0.2', 'setosa']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.rdd.map(list).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Display contents of a dataframe\n",
    "\n",
    "##### a. In table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. all contents of a dataframe as a list of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Sepal_Length='5.1', Sepal_Width='3.5', Petal_Length='1.4', Petal_Width='0.2', Species='setosa'),\n",
       " Row(Sepal_Length='4.9', Sepal_Width='3.0', Petal_Length='1.4', Petal_Width='0.2', Species='setosa'),\n",
       " Row(Sepal_Length='4.7', Sepal_Width='3.2', Petal_Length='1.3', Petal_Width='0.2', Species='setosa'),\n",
       " Row(Sepal_Length='4.6', Sepal_Width='3.1', Petal_Length='1.5', Petal_Width='0.2', Species='setosa'),\n",
       " Row(Sepal_Length='5.0', Sepal_Width='3.6', Petal_Length='1.4', Petal_Width='0.2', Species='setosa')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.take(5)   # or use collect() to show all the elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Sepal_Length='5.1', Sepal_Width='3.5', Petal_Length='1.4', Petal_Width='0.2', Species='setosa'),\n",
       " Row(Sepal_Length='4.9', Sepal_Width='3.0', Petal_Length='1.4', Petal_Width='0.2', Species='setosa'),\n",
       " Row(Sepal_Length='4.7', Sepal_Width='3.2', Petal_Length='1.3', Petal_Width='0.2', Species='setosa'),\n",
       " Row(Sepal_Length='4.6', Sepal_Width='3.1', Petal_Length='1.5', Petal_Width='0.2', Species='setosa'),\n",
       " Row(Sepal_Length='5.0', Sepal_Width='3.6', Petal_Length='1.4', Petal_Width='0.2', Species='setosa')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data selection (i.e., selecting particular column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|Sepal_Length|Species|\n",
      "+------------+-------+\n",
      "|         5.1| setosa|\n",
      "|         4.9| setosa|\n",
      "|         4.7| setosa|\n",
      "|         4.6| setosa|\n",
      "|         5.0| setosa|\n",
      "+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select('Sepal_Length', 'Species').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Sepal_Length='5.1', Sepal_Width='3.5', ID='1'),\n",
       " Row(Sepal_Length='4.9', Sepal_Width='3', ID='2'),\n",
       " Row(Sepal_Length='4.7', Sepal_Width='3.2', ID='3'),\n",
       " Row(Sepal_Length='4.6', Sepal_Width='3.1', ID='4'),\n",
       " Row(Sepal_Length='5', Sepal_Width='3.6', ID='5')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris1_df1 = spark.read.csv(path = 'iris\\\\merge\\\\iris_merge1.csv', sep = ',', header = True)\n",
    "iris1_df1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID='1', Petal_Length='1.4', Petal_Width='0.2', Species='setosa'),\n",
       " Row(ID='2', Petal_Length='1.4', Petal_Width='0.2', Species='setosa'),\n",
       " Row(ID='3', Petal_Length='1.3', Petal_Width='0.2', Species='setosa'),\n",
       " Row(ID='4', Petal_Length='1.5', Petal_Width='0.2', Species='setosa'),\n",
       " Row(ID='5', Petal_Length='1.4', Petal_Width='0.2', Species='setosa')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris2_df2 = spark.read.csv(path = 'iris\\\\merge\\\\iris_merge2.csv', sep = ',', header = True)\n",
    "iris2_df2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID='1', Sepal_Length='5.1', Sepal_Width='3.5', Petal_Length='1.4', Petal_Width='0.2', Species='setosa'),\n",
       " Row(ID='2', Sepal_Length='4.9', Sepal_Width='3', Petal_Length='1.4', Petal_Width='0.2', Species='setosa'),\n",
       " Row(ID='3', Sepal_Length='4.7', Sepal_Width='3.2', Petal_Length='1.3', Petal_Width='0.2', Species='setosa'),\n",
       " Row(ID='4', Sepal_Length='4.6', Sepal_Width='3.1', Petal_Length='1.5', Petal_Width='0.2', Species='setosa'),\n",
       " Row(ID='5', Sepal_Length='5', Sepal_Width='3.6', Petal_Length='1.4', Petal_Width='0.2', Species='setosa')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris1_df1.join(other = iris2_df2, on = 'ID', how = 'inner').take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Union\n",
    "\n",
    "Two data frames with similar structures can be joined row-wise using the union function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Sepal.Length='5', Sepal.Width='3', Petal.Length='1', Petal.Width='0'),\n",
       " Row(Sepal.Length='4.6', Sepal.Width=None, Petal.Length='2', Petal.Width='0.1'),\n",
       " Row(Sepal.Length='7.2', Sepal.Width='3.1', Petal.Length='5.1', Petal.Width='1'),\n",
       " Row(Sepal.Length='8', Sepal.Width='4', Petal.Length='7', Petal.Width='2')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris1_df1 = spark.read.csv(path = 'iris\\\\union\\\\iris_union1.csv', sep = ',', header = True)\n",
    "iris1_df1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Sepal.Length='10', Sepal.Width='6', Petal.Length='2', Petal.Width='0'),\n",
       " Row(Sepal.Length='9.2', Sepal.Width='0', Petal.Length='4', Petal.Width='0.2'),\n",
       " Row(Sepal.Length='14.4', Sepal.Width='6.2', Petal.Length='10.2', Petal.Width='2'),\n",
       " Row(Sepal.Length='16', Sepal.Width='8', Petal.Length='14', Petal.Width='4')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris2_df2 = spark.read.csv(path = 'iris/union/iris_union2.csv', sep = ',', header = True)\n",
    "iris2_df2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+\n",
      "|Sepal.Length|Sepal.Width|Petal.Length|Petal.Width|\n",
      "+------------+-----------+------------+-----------+\n",
      "|           5|          3|           1|          0|\n",
      "|         4.6|       null|           2|        0.1|\n",
      "|         7.2|        3.1|         5.1|          1|\n",
      "|           8|          4|           7|          2|\n",
      "|          10|          6|           2|          0|\n",
      "|         9.2|          0|           4|        0.2|\n",
      "|        14.4|        6.2|        10.2|          2|\n",
      "|          16|          8|          14|          4|\n",
      "+------------+-----------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris1_df1.union(iris2_df2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Get column names of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width', 'Species']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Retrieve Schema of the Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(Sepal_Length,StringType,true),StructField(Sepal_Width,StringType,true),StructField(Petal_Length,StringType,true),StructField(Petal_Width,StringType,true),StructField(Species,StringType,true)))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure for data frame can be defined with the help of StructField and StructType function. \n",
    "\n",
    "__StructType__ is the data type representing a Row. It consisting of a list of StructField. StructField is a field in StructType. It's arguments are\n",
    "\n",
    "- __name__ - name of the columns\n",
    "- __datatype__ - data type of the column\n",
    "- __nullable__ - boolean value defining if the column is nullable or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Display Datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sepal_Length', 'string'),\n",
       " ('Sepal_Width', 'string'),\n",
       " ('Petal_Length', 'string'),\n",
       " ('Petal_Width', 'string'),\n",
       " ('Species', 'string')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Default structure of a dataframe\n",
    "\n",
    "When the data frame is created from an RDD it can be observed from the below result that the Data Frame has no column header.\n",
    "\n",
    "In addition, when data is being imported from a csv file, there might be situations when a float column is defined as a string column. To overcome this issue, a structure needs to impose on the data to be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+------+\n",
      "| _1| _2| _3| _4|    _5|\n",
      "+---+---+---+---+------+\n",
      "|5.1|3.5|1.4|0.2|setosa|\n",
      "|4.9|3.0|1.4|0.2|setosa|\n",
      "|4.7|3.2|1.3|0.2|setosa|\n",
      "|4.6|3.1|1.5|0.2|setosa|\n",
      "|5.0|3.6|1.4|0.2|setosa|\n",
      "|5.4|3.9|1.7|0.4|setosa|\n",
      "|4.6|3.4|1.4|0.3|setosa|\n",
      "|5.0|3.4|1.5|0.2|setosa|\n",
      "|4.4|2.9|1.4|0.2|setosa|\n",
      "|4.9|3.1|1.5|0.1|setosa|\n",
      "|5.4|3.7|1.5|0.2|setosa|\n",
      "|4.8|3.4|1.6|0.2|setosa|\n",
      "|4.8|3.0|1.4|0.1|setosa|\n",
      "|4.3|3.0|1.1|0.1|setosa|\n",
      "|5.8|4.0|1.2|0.2|setosa|\n",
      "|5.7|4.4|1.5|0.4|setosa|\n",
      "|5.4|3.9|1.3|0.4|setosa|\n",
      "|5.1|3.5|1.4|0.3|setosa|\n",
      "|5.7|3.8|1.7|0.3|setosa|\n",
      "|5.1|3.8|1.5|0.3|setosa|\n",
      "+---+---+---+---+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris1 = sc.textFile(\"iris/iris_site.csv\").map(lambda line: line.split(\",\"))\n",
    "iris1_split = iris1.map(lambda var1: [float(var1[0]), float(var1[1]), float(var1[2]), float(var1[3]), var1[4]])\n",
    "df1=spark.createDataFrame(iris1_split)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Defining structure for dataframe\n",
    "\n",
    "A table contains multiple fields. So, while defining the structure of a table we need to define\n",
    "- number of columns\n",
    "- name of each column\n",
    "- data type of each column\n",
    "\n",
    "For a structured data, all the rows have the same structure. Here, we define the structure of the row using StructType class. It takes as an argument, a collection of StructField class objects, which is used to define the metadata about the columns in each row.\n",
    "\n",
    "StructField takes as input\n",
    "- name - name of the columns\n",
    "- datatype - data type of the column\n",
    "- nullable - boolean value defining if the column is nullable or not\n",
    "\n",
    "In the below example, the structure for the iris data set is defined. It can be observed that there is a single StructType function, for which five StructField objects are passed as arguments, where each StructField corresponds to one column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(Sepal_Length,FloatType,true),StructField(Sepal_Width,FloatType,true),StructField(Petal_Length,FloatType,true),StructField(Petal_Width,FloatType,true),StructField(Species,StringType,true)))\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, FloatType, StringType\n",
    "\n",
    "iris_schema = pyspark.sql.types.StructType([\n",
    "    StructField('Sepal_Length', FloatType(), True),\n",
    "    StructField('Sepal_Width', FloatType(), True),\n",
    "    StructField('Petal_Length', FloatType(), True),\n",
    "    StructField('Petal_Width', FloatType(), True),\n",
    "    StructField('Species', StringType(), True),\n",
    "])\n",
    "\n",
    "print(iris_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning Defined Structure to Data Frame\n",
    "\n",
    "When the data frame is created using an RDD, the defined schema can be assigned as highlighted in the below code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2| setosa|\n",
      "|         4.8|        3.4|         1.6|        0.2| setosa|\n",
      "|         4.8|        3.0|         1.4|        0.1| setosa|\n",
      "|         4.3|        3.0|         1.1|        0.1| setosa|\n",
      "|         5.8|        4.0|         1.2|        0.2| setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4| setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4| setosa|\n",
      "|         5.1|        3.5|         1.4|        0.3| setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3| setosa|\n",
      "|         5.1|        3.8|         1.5|        0.3| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1=spark.createDataFrame(iris1_split, iris_schema)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing with the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Sepal_Length=5.099999904632568, Sepal_Width=3.5, Petal_Length=1.399999976158142, Petal_Width=0.20000000298023224, Species='setosa'),\n",
       " Row(Sepal_Length=4.900000095367432, Sepal_Width=3.0, Petal_Length=1.399999976158142, Petal_Width=0.20000000298023224, Species='setosa'),\n",
       " Row(Sepal_Length=4.699999809265137, Sepal_Width=3.200000047683716, Petal_Length=1.2999999523162842, Petal_Width=0.20000000298023224, Species='setosa'),\n",
       " Row(Sepal_Length=4.599999904632568, Sepal_Width=3.0999999046325684, Petal_Length=1.5, Petal_Width=0.20000000298023224, Species='setosa'),\n",
       " Row(Sepal_Length=5.0, Sepal_Width=3.5999999046325684, Petal_Length=1.399999976158142, Petal_Width=0.20000000298023224, Species='setosa')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris1_df1 = spark.read.csv(path = 'iris/iris.csv', sep = ',', header = True,schema=iris_schema)\n",
    "iris1_df1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sepal_Length', 'float'),\n",
       " ('Sepal_Width', 'float'),\n",
       " ('Petal_Length', 'float'),\n",
       " ('Petal_Width', 'float'),\n",
       " ('Species', 'string')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris1_df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Converting Datatype\n",
    "\n",
    "Data type of a particular column can be changed by first selecting those columns using select function and then changing its type using the cast function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sepal_Length', 'string'),\n",
       " ('Sepal_Width', 'string'),\n",
       " ('Petal_Length', 'string'),\n",
       " ('Petal_Width', 'string'),\n",
       " ('Species', 'string')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris1_df1 = spark.read.csv(path = 'iris/iris.csv', sep = ',', header = True)\n",
    "iris1_df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|Petal_Length|Petal_Width|\n",
      "+------------+-----------+\n",
      "|         1.4|        0.2|\n",
      "|         1.4|        0.2|\n",
      "|         1.3|        0.2|\n",
      "|         1.5|        0.2|\n",
      "|         1.4|        0.2|\n",
      "+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris2 = iris1_df1.select(iris1_df1['Petal_Length'].cast('float'), iris1_df1['Petal_Width'].cast('float'))\n",
    "iris2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris1_df1 = spark.read.csv(path = 'iris/iris.csv', sep = ',', header = True,schema=iris_schema)\n",
    "iris1_df1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping column Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris1_df1.drop('Speices').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Sorting Data\n",
    "\n",
    "Data can be sorted based on a particular column of the data frame using sort function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+---------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|  Species|\n",
      "+------------+-----------+------------+-----------+---------+\n",
      "|         7.7|        2.6|         6.9|        2.3|virginica|\n",
      "|         7.7|        2.8|         6.7|        2.0|virginica|\n",
      "|         7.7|        3.8|         6.7|        2.2|virginica|\n",
      "|         7.6|        3.0|         6.6|        2.1|virginica|\n",
      "|         7.9|        3.8|         6.4|        2.0|virginica|\n",
      "|         7.3|        2.9|         6.3|        1.8|virginica|\n",
      "|         7.4|        2.8|         6.1|        1.9|virginica|\n",
      "|         7.7|        3.0|         6.1|        2.3|virginica|\n",
      "|         7.2|        3.6|         6.1|        2.5|virginica|\n",
      "|         6.3|        3.3|         6.0|        2.5|virginica|\n",
      "|         7.2|        3.2|         6.0|        1.8|virginica|\n",
      "|         7.1|        3.0|         5.9|        2.1|virginica|\n",
      "|         6.8|        3.2|         5.9|        2.3|virginica|\n",
      "|         6.7|        2.5|         5.8|        1.8|virginica|\n",
      "|         6.5|        3.0|         5.8|        2.2|virginica|\n",
      "|         7.2|        3.0|         5.8|        1.6|virginica|\n",
      "|         6.7|        3.3|         5.7|        2.5|virginica|\n",
      "|         6.9|        3.2|         5.7|        2.3|virginica|\n",
      "|         6.7|        3.3|         5.7|        2.1|virginica|\n",
      "|         6.7|        3.1|         5.6|        2.4|virginica|\n",
      "+------------+-----------+------------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris1_df1 = spark.read.csv(path = 'iris/iris.csv', sep = ',', header = True, schema=iris_schema)\n",
    "iris1_df1.sort('Petal_Length', ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Filtering Data Based on a Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|Sepal_Length|Species|\n",
      "+------------+-------+\n",
      "|         5.1| setosa|\n",
      "|         4.9| setosa|\n",
      "|         4.7| setosa|\n",
      "|         4.6| setosa|\n",
      "|         5.0| setosa|\n",
      "+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris1_df1.select('Sepal_Length', 'Species').filter(\"Species == 'setosa'\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To filter only the flowers where 'Species' is either 'setosa' or 'versicolor'  isin function can be used as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2| setosa|\n",
      "|         4.8|        3.4|         1.6|        0.2| setosa|\n",
      "|         4.8|        3.0|         1.4|        0.1| setosa|\n",
      "|         4.3|        3.0|         1.1|        0.1| setosa|\n",
      "|         5.8|        4.0|         1.2|        0.2| setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4| setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4| setosa|\n",
      "|         5.1|        3.5|         1.4|        0.3| setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3| setosa|\n",
      "|         5.1|        3.8|         1.5|        0.3| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris1_df1[iris1_df1['Species'].isin(['setosa', 'versicolor'])].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------+----+\n",
      "|age|income|gender|marital|buys|\n",
      "+---+------+------+-------+----+\n",
      "| 24|130000|Female|Married|  No|\n",
      "| 23|140000|Female| Single|  No|\n",
      "| 27|150000|Female|Married| Yes|\n",
      "| 51| 70000|Female|Married| Yes|\n",
      "| 53| 50000|  Male|Married| Yes|\n",
      "+---+------+------+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "buy = spark.read.csv(path = 'iris/buy.csv', sep = ',', header = True)\n",
    "buy.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------+----+\n",
      "|age|income|gender|marital|buys|\n",
      "+---+------+------+-------+----+\n",
      "| 51| 70000|Female|Married| Yes|\n",
      "| 53| 50000|  Male|Married| Yes|\n",
      "| 56| 40000|  Male| Single|  No|\n",
      "| 61| 90000|  Male|Married| Yes|\n",
      "| 55|120000|Female| Single|  No|\n",
      "+---+------+------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the count of customers whose age is greater than 50\n",
    "buy.filter(\"age > 50\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------+----+\n",
      "|age|income|gender|marital|buys|\n",
      "+---+------+------+-------+----+\n",
      "| 51| 70000|Female|Married| Yes|\n",
      "| 53| 50000|  Male|Married| Yes|\n",
      "| 56| 40000|  Male| Single|  No|\n",
      "| 61| 90000|  Male|Married| Yes|\n",
      "| 55|120000|Female| Single|  No|\n",
      "+---+------+------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "buy.filter(buy.age > 50).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. distinct() and Distinct Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|   Species|\n",
      "+----------+\n",
      "| virginica|\n",
      "|versicolor|\n",
      "|    setosa|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris1_df1.select('Species').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of values in a particular data frame can be retrieved using count function. In the below example, the count of distinct values in 'Species' column is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris1_df1.select('Species').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Aggregation\n",
    "\n",
    "Values of a particular column inside a data frame can be aggregated using `agg` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|sum(Sepal_Length)|\n",
      "+-----------------+\n",
      "|876.4999990463257|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris1_df1.agg({'Sepal_Length': \"sum\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating Grouped Data\n",
    "\n",
    "Aggregation for values of a particular column can be performed for several groups by combining `groupBy` with `agg` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|   Species|avg(Sepal_Length)|\n",
      "+----------+-----------------+\n",
      "| virginica|6.588000001907349|\n",
      "|versicolor|5.935999975204468|\n",
      "|    setosa|5.006000003814697|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris1_df1.groupBy('Species').agg({'Sepal_Length':'mean'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Statistical summary of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+---------+\n",
      "|summary|      Sepal_length|       Sepal_Width|      Petal_Length|       Petal_Width|  Species|\n",
      "+-------+------------------+------------------+------------------+------------------+---------+\n",
      "|  count|               150|               150|               150|               150|      150|\n",
      "|   mean| 5.843333326975505|3.0573333358764647|3.7579999883969624|1.1993333247800668|     null|\n",
      "| stddev|0.8280661128539085|0.4358662838657101|1.7652982279508533|0.7622376591453995|     null|\n",
      "|    min|               4.3|               2.0|               1.0|               0.1|   setosa|\n",
      "|    max|               7.9|               4.4|               6.9|               2.5|virginica|\n",
      "+-------+------------------+------------------+------------------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris1_df1.describe(['Sepal_length', 'Sepal_Width', 'Petal_Length', 'Petal_Width', 'Species']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Calculating Quantiles of data\n",
    "\n",
    "Quantiles of a column in a dataframe can be calculated using `approxQuantile` function.\n",
    "\n",
    "Here calculating the 490th, 60th and 80th quantile is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.599999904632568, 6.099999904632568, 6.5]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris1_df1.approxQuantile(col = 'Sepal_Length', probabilities = [0.4, 0.6, 0.8], relativeError=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Multi-dimensional view of data\n",
    "\n",
    "Looking at data in several dimensions, for eg: sales by region, sales by sales_representative, sales by month, etc. Such capability is provided in numerous decision support applications under various function names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+------------------+------------------+-------------------+\n",
      "|   Species|avg(Sepal_Length)|  avg(Sepal_Width)| avg(Petal_Length)|   avg(Petal_Width)|\n",
      "+----------+-----------------+------------------+------------------+-------------------+\n",
      "|      null|5.843333326975505|3.0573333358764647|3.7579999883969624| 1.1993333247800668|\n",
      "|    setosa|5.006000003814697|3.4280000066757204|1.4619999957084655|0.24600000485777854|\n",
      "| virginica|6.588000001907349|2.9739999914169313| 5.551999988555909| 2.0259999775886537|\n",
      "|versicolor|5.935999975204468| 2.770000009536743| 4.259999980926514| 1.3259999918937684|\n",
      "+----------+-----------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris1_df1.cube('Species').mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Correlation and covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance:  1.274315421293779\n"
     ]
    }
   ],
   "source": [
    "print(\"Covariance: \", iris1_df1.cov('Sepal_Length', 'Petal_Length'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation:  0.871753784204251\n"
     ]
    }
   ],
   "source": [
    "print(\"Correlation: \", iris1_df1.corr('Sepal_Length', 'Petal_Length'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+----------+---------+\n",
      "|Species_Species|setosa|versicolor|virginica|\n",
      "+---------------+------+----------+---------+\n",
      "|      virginica|     0|         0|       50|\n",
      "|         setosa|    50|         0|        0|\n",
      "|     versicolor|     0|        50|        0|\n",
      "+---------------+------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris1_df1.crosstab('Species', 'Species').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
