{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H:\\\\Spark\\\\spark-3.0.0-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from a sample textfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = sc.textFile('sample_file.txt')\n",
    "type(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hi,', 'How', 'are', 'you?'],\n",
       " ['My', 'name', 'is', 'Jeswin', 'George.'],\n",
       " ['I', 'am', 'studying', 'spark.']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = words.map(lambda line:line.split(' '))\n",
    "words.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from  a string data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'Hello, How are you?'.split(\" \")\n",
    "mdata = sc.parallelize(data,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello,', 'How', 'are', 'you?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations\n",
    "## Filitering operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered RDD is:  ['spark', 'spark vs hadoop', 'pyspark', 'spark and pyspark']\n"
     ]
    }
   ],
   "source": [
    "words = sc.parallelize(['scala', 'java', 'hadoop', 'spark', 'spark vs hadoop', 'pyspark', 'spark and pyspark'])\n",
    "# transformation\n",
    "words_filter = words.filter(lambda x: 'spark' in x)\n",
    "# action\n",
    "filtered = words_filter.collect()\n",
    "print('Filtered RDD is: ', filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered RDD is:  ['scala', 'java', 'hadoop']\n"
     ]
    }
   ],
   "source": [
    "# transformation\n",
    "words_diff_filter = words.filter(lambda x: 'spark' not in x)\n",
    "# action\n",
    "filtered_diff = words_diff_filter.collect()\n",
    "print('Filtered RDD is: ', filtered_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered RDD is:  ['SCALA', 'JAVA', 'HADOOP', 'SPARK', 'SPARK VS HADOOP', 'PYSPARK', 'SPARK AND PYSPARK']\n"
     ]
    }
   ],
   "source": [
    "# transformation\n",
    "words_diff_filter = words.map(lambda x: x.upper())   # used map here\n",
    "# action\n",
    "filtered_diff = words_diff_filter.collect()\n",
    "print('Filtered RDD is: ', filtered_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rdds can be used as an iterable too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome', 'to', 'Edureka', 'Spark', 'Certification', 'training']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'Welcome to Edureka Spark Certification training'.split(' ')\n",
    "rdd = sc.parallelize(data)\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest word is Certification with length 13\n"
     ]
    }
   ],
   "source": [
    "# find largest word\n",
    "max_w1 = 0\n",
    "for word in rdd.collect():\n",
    "    if len(word)>max_w1:\n",
    "        max_w1 = len(word)\n",
    "        largest_word = word\n",
    "\n",
    "print(\"Largest word is {} with length {}\".format(largest_word, max_w1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between map and flatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi, How are you?', 'My name is Jeswin George.', 'I am studying spark.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = sc.textFile('sample_file.txt')\n",
    "words.collect()  # Each line is read as  a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using map to apply a function each string element "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hi,', 'How', 'are', 'you?'],\n",
       " ['My', 'name', 'is', 'Jeswin', 'George.'],\n",
       " ['I', 'am', 'studying', 'spark.']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_map = words.map(lambda line:line.split(' '))\n",
    "words_map.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using flatMap each element inside the list of lists will be taken as a single element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi,',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you?',\n",
       " 'My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Jeswin',\n",
       " 'George.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'studying',\n",
       " 'spark.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_flatmap = words.flatMap(lambda line:line.split(' '))\n",
    "words_flatmap.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking the flatMapped data again and applying flatMap on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H',\n",
       " 'i',\n",
       " ',',\n",
       " 'H',\n",
       " 'o',\n",
       " 'w',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " 'y',\n",
       " 'o',\n",
       " 'u',\n",
       " '?',\n",
       " 'M',\n",
       " 'y',\n",
       " 'n',\n",
       " 'a',\n",
       " 'm',\n",
       " 'e',\n",
       " 'i',\n",
       " 's',\n",
       " 'J',\n",
       " 'e',\n",
       " 's',\n",
       " 'w',\n",
       " 'i',\n",
       " 'n',\n",
       " 'G',\n",
       " 'e',\n",
       " 'o',\n",
       " 'r',\n",
       " 'g',\n",
       " 'e',\n",
       " '.',\n",
       " 'I',\n",
       " 'a',\n",
       " 'm',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'd',\n",
       " 'y',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " 's',\n",
       " 'p',\n",
       " 'a',\n",
       " 'r',\n",
       " 'k',\n",
       " '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = words_flatmap.flatMap(lambda word:(word))\n",
    "w1.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize('Welcome to Edureka')\n",
    "data.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W', 'e', 'l', 'c', 'o', 'm', ' ', 't', 'E', 'd', 'u', 'r', 'k', 'a']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sortBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to', 'Hello,', 'Welcome', 'Edureka']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize('Hello, Welcome to Edureka'.split(\" \"))\n",
    "rdd1.sortBy(lambda line: len(line)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'jan', 2016), (3, 'nov', 2014), (16, 'feb', 2014)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(((1, 'jan', 2016), (3, 'nov', 2014), (16, 'feb', 2014)))\n",
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'jan', 2016), (5, 'nov', 2014), (16, 'mar', 2014)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = sc.parallelize(((1, 'jan', 2016), (5, 'nov', 2014), (16, 'mar', 2014)))\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'jan', 2016)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.intersection(rdd2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello,', 'Welcome', 'to', 'Edureka', 'Hi,', 'Goto', 'to', 'floor', '2']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_rdd = sc.parallelize('Hello, Welcome to Edureka'.split(\" \"))\n",
    "input2_rdd = sc.parallelize('Hi, Goto to floor 2'.split(' '))\n",
    "input_rdd.union(input2_rdd).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
